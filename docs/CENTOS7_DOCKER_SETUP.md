# CentOS 7 Docker ë°°í¬ ê°€ì´ë“œ

CentOS 7ì—ì„œ Dockerë¥¼ ì‚¬ìš©í•˜ì—¬ APAS ì‹œìŠ¤í…œì„ ë°°í¬í•˜ê³ , ì—…ë¡œë“œ íŒŒì¼ì„ í˜¸ìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ì— ì €ì¥í•˜ëŠ” ì™„ì „í•œ ê°€ì´ë“œì…ë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨

1. [ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­](#ì‹œìŠ¤í…œ-ìš”êµ¬ì‚¬í•­)
2. [Docker ì„¤ì¹˜](#docker-ì„¤ì¹˜)
3. [ë””ë ‰í† ë¦¬ êµ¬ì¡° ì„¤ì •](#ë””ë ‰í† ë¦¬-êµ¬ì¡°-ì„¤ì •)
4. [Docker Compose ì„¤ì •](#docker-compose-ì„¤ì •)
5. [í™˜ê²½ ë³€ìˆ˜ ì„¤ì •](#í™˜ê²½-ë³€ìˆ˜-ì„¤ì •)
6. [ë°°í¬ ì‹¤í–‰](#ë°°í¬-ì‹¤í–‰)
7. [íŒŒì¼ ì €ì¥ ê´€ë¦¬](#íŒŒì¼-ì €ì¥-ê´€ë¦¬)
8. [ìš´ì˜ ê´€ë¦¬](#ìš´ì˜-ê´€ë¦¬)

---

## ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

### ìµœì†Œ ì‚¬ì–‘

- **OS**: CentOS 7.x
- **CPU**: 2 Core ì´ìƒ
- **RAM**: 4GB ì´ìƒ (ê¶Œì¥ 8GB)
- **Disk**: 20GB ì´ìƒ ì—¬ìœ  ê³µê°„
- **Network**: ì¸í„°ë„· ì—°ê²° í•„ìš”

### í•„ìš”í•œ í¬íŠ¸

- **3000**: Frontend (Next.js)
- **3001**: Backend API (Express.js)
- **5432**: PostgreSQL (ì„ íƒ - Supabase ì‚¬ìš© ì‹œ ë¶ˆí•„ìš”)

---

## Docker ì„¤ì¹˜

### ìë™ ì„¤ì¹˜ (ê¶Œì¥)

```bash
cd /path/to/Water_AI_Report_Gen
chmod +x scripts/install-docker-centos7.sh
./scripts/install-docker-centos7.sh
```

### ì„¤ì¹˜ í™•ì¸

```bash
docker --version
docker-compose --version
sudo systemctl status docker
```

---

## ë””ë ‰í† ë¦¬ êµ¬ì¡° ì„¤ì •

### 1. ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±

```bash
# ì• í”Œë¦¬ì¼€ì´ì…˜ ë£¨íŠ¸ ë””ë ‰í† ë¦¬
sudo mkdir -p /opt/apas

# ì—…ë¡œë“œ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬
sudo mkdir -p /opt/apas/data/uploads

# ë¡œê·¸ ë””ë ‰í† ë¦¬
sudo mkdir -p /opt/apas/logs

# ë°±ì—… ë””ë ‰í† ë¦¬
sudo mkdir -p /opt/apas/backups

# PostgreSQL ë°ì´í„° ë””ë ‰í† ë¦¬ (ë¡œì»¬ DB ì‚¬ìš© ì‹œ)
sudo mkdir -p /opt/apas/data/postgres

# ê¶Œí•œ ì„¤ì • (Docker ì»¨í…Œì´ë„ˆì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡)
sudo chown -R 1000:1000 /opt/apas/data
sudo chmod -R 755 /opt/apas/data
```

### 2. ìµœì¢… ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
/opt/apas/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/          # ì—…ë¡œë“œëœ íŒŒì¼ (PDF, DOCX)
â”‚   â”‚   â”œâ”€â”€ documents/    # ì›ë³¸ ë¬¸ì„œ
â”‚   â”‚   â”œâ”€â”€ generated/    # ìƒì„±ëœ ë¬¸ì„œ
â”‚   â”‚   â””â”€â”€ temp/         # ì„ì‹œ íŒŒì¼
â”‚   â””â”€â”€ postgres/         # PostgreSQL ë°ì´í„° (ë¡œì»¬ DB ì‚¬ìš© ì‹œ)
â”œâ”€â”€ logs/                 # ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸
â”‚   â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ backend/
â””â”€â”€ backups/              # ë°±ì—… íŒŒì¼
```

---

## Docker Compose ì„¤ì •

### 1. `docker-compose.yml` ìƒì„±

í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ë‹¤ìŒ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

**`docker-compose.yml`**:

```yaml
version: '3.8'

services:
  # Frontend Service (Next.js)
  frontend:
    build:
      context: ./frontend
      dockerfile: ../docker/Dockerfile.frontend
    container_name: apas-frontend
    restart: unless-stopped
    ports:
      - '3000:3000'
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_API_URL=http://localhost:3001
      - NEXT_PUBLIC_SUPABASE_URL=${SUPABASE_URL}
      - NEXT_PUBLIC_SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
    depends_on:
      - backend
    networks:
      - apas-network
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:3000/api/health']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Backend Service (Express.js)
  backend:
    build:
      context: ./backend
      dockerfile: ../docker/Dockerfile.backend
    container_name: apas-backend
    restart: unless-stopped
    ports:
      - '3001:3001'
    environment:
      - NODE_ENV=production
      - PORT=3001
      - DATABASE_URL=${DATABASE_URL}
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY}
      - SUPABASE_STORAGE_BUCKET=${SUPABASE_STORAGE_BUCKET}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - JWT_SECRET=${JWT_SECRET}
      - JWT_EXPIRES_IN=${JWT_EXPIRES_IN}
      - CORS_ORIGIN=${CORS_ORIGIN}
      - UPLOAD_DIR=/app/uploads
    volumes:
      # í˜¸ìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì»¨í…Œì´ë„ˆì— ë§ˆìš´íŠ¸
      - /opt/apas/data/uploads:/app/uploads
      - /opt/apas/logs/backend:/app/logs
    networks:
      - apas-network
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:3001/health']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # PostgreSQL (ì„ íƒ - Supabase ëŒ€ì‹  ë¡œì»¬ DB ì‚¬ìš© ì‹œ)
  # postgres:
  #   image: postgres:15-alpine
  #   container_name: apas-postgres
  #   restart: unless-stopped
  #   ports:
  #     - "5432:5432"
  #   environment:
  #     - POSTGRES_USER=${POSTGRES_USER:-apas}
  #     - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
  #     - POSTGRES_DB=${POSTGRES_DB:-apas_db}
  #   volumes:
  #     - /opt/apas/data/postgres:/var/lib/postgresql/data
  #   networks:
  #     - apas-network
  #   healthcheck:
  #     test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-apas}"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5

  # Redis (ìºì‹± - ì„ íƒ)
  # redis:
  #   image: redis:7-alpine
  #   container_name: apas-redis
  #   restart: unless-stopped
  #   ports:
  #     - "6379:6379"
  #   volumes:
  #     - /opt/apas/data/redis:/data
  #   networks:
  #     - apas-network
  #   healthcheck:
  #     test: ["CMD", "redis-cli", "ping"]
  #     interval: 10s
  #     timeout: 3s
  #     retries: 5

  # Nginx (ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ - ì„ íƒ)
  # nginx:
  #   image: nginx:alpine
  #   container_name: apas-nginx
  #   restart: unless-stopped
  #   ports:
  #     - "80:80"
  #     - "443:443"
  #   volumes:
  #     - ./docker/nginx.conf:/etc/nginx/nginx.conf:ro
  #     - /opt/apas/logs/nginx:/var/log/nginx
  #   depends_on:
  #     - frontend
  #     - backend
  #   networks:
  #     - apas-network

networks:
  apas-network:
    driver: bridge

volumes:
  postgres-data:
  redis-data:
```

---

## Dockerfile ìƒì„±

### 1. Frontend Dockerfile

**`docker/Dockerfile.frontend`**:

```dockerfile
# Stage 1: Dependencies
FROM node:18-alpine AS deps
WORKDIR /app

# Copy root package files
COPY package*.json ./
COPY frontend/package*.json ./frontend/

# Install dependencies
RUN npm ci --workspace=frontend --legacy-peer-deps

# Stage 2: Builder
FROM node:18-alpine AS builder
WORKDIR /app

# Copy dependencies
COPY --from=deps /app/node_modules ./node_modules
COPY --from=deps /app/frontend/node_modules ./frontend/node_modules

# Copy source code
COPY frontend ./frontend
COPY package*.json ./

# Build arguments (í™˜ê²½ ë³€ìˆ˜)
ARG NEXT_PUBLIC_API_URL
ARG NEXT_PUBLIC_SUPABASE_URL
ARG NEXT_PUBLIC_SUPABASE_ANON_KEY

ENV NEXT_PUBLIC_API_URL=$NEXT_PUBLIC_API_URL
ENV NEXT_PUBLIC_SUPABASE_URL=$NEXT_PUBLIC_SUPABASE_URL
ENV NEXT_PUBLIC_SUPABASE_ANON_KEY=$NEXT_PUBLIC_SUPABASE_ANON_KEY

# Build Next.js
WORKDIR /app/frontend
RUN npm run build

# Stage 3: Runner
FROM node:18-alpine AS runner
WORKDIR /app

ENV NODE_ENV=production
ENV NEXT_TELEMETRY_DISABLED=1

# Create user
RUN addgroup --system --gid 1001 nodejs
RUN adduser --system --uid 1001 nextjs

# Copy built application
COPY --from=builder /app/frontend/public ./public
COPY --from=builder /app/frontend/.next/standalone ./
COPY --from=builder /app/frontend/.next/static ./.next/static

# Set ownership
RUN chown -R nextjs:nodejs /app

USER nextjs

EXPOSE 3000

ENV PORT=3000
ENV HOSTNAME="0.0.0.0"

CMD ["node", "server.js"]
```

### 2. Backend Dockerfile

**`docker/Dockerfile.backend`**:

```dockerfile
# Stage 1: Dependencies
FROM node:18-alpine AS deps
WORKDIR /app

# Install build tools (for native dependencies)
RUN apk add --no-cache python3 make g++

# Copy package files
COPY package*.json ./
COPY backend/package*.json ./backend/
COPY backend/prisma ./backend/prisma

# Install dependencies
RUN npm ci --workspace=backend --legacy-peer-deps

# Generate Prisma Client
WORKDIR /app/backend
RUN npx prisma generate

# Stage 2: Builder
FROM node:18-alpine AS builder
WORKDIR /app

# Copy dependencies
COPY --from=deps /app/node_modules ./node_modules
COPY --from=deps /app/backend/node_modules ./backend/node_modules

# Copy source code
COPY backend ./backend
COPY package*.json ./

# Build TypeScript
WORKDIR /app/backend
RUN npm run build

# Stage 3: Runner
FROM node:18-alpine AS runner
WORKDIR /app

ENV NODE_ENV=production

# Install curl for healthcheck
RUN apk add --no-cache curl

# Create user
RUN addgroup --system --gid 1001 nodejs
RUN adduser --system --uid 1001 nodejs

# Copy built application
COPY --from=builder /app/backend/dist ./dist
COPY --from=builder /app/backend/node_modules ./node_modules
COPY --from=builder /app/backend/package*.json ./

# Create upload directory
RUN mkdir -p /app/uploads /app/logs
RUN chown -R nodejs:nodejs /app

USER nodejs

EXPOSE 3001

CMD ["node", "dist/index.js"]
```

### 3. `.dockerignore` íŒŒì¼ ìƒì„±

**`frontend/.dockerignore`**:

```
node_modules
.next
.git
.gitignore
.env*.local
.env.production
*.log
npm-debug.log*
.DS_Store
coverage
.vscode
.idea
```

**`backend/.dockerignore`**:

```
node_modules
dist
.git
.gitignore
.env*.local
.env.production
*.log
npm-debug.log*
.DS_Store
coverage
.vscode
.idea
uploads
logs
```

---

## í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

### 1. `.env.production` íŒŒì¼ ìƒì„±

í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ìƒì„±:

**`.env.production`**:

```bash
# ========================================
# APAS Production Environment Variables
# ========================================

# Database (Supabase PostgreSQL)
DATABASE_URL=postgresql://postgres:[YOUR-PASSWORD]@db.[YOUR-PROJECT-REF].supabase.co:5432/postgres

# Supabase
SUPABASE_URL=https://[YOUR-PROJECT-REF].supabase.co
SUPABASE_SERVICE_KEY=your_supabase_service_role_key
SUPABASE_ANON_KEY=your_supabase_anon_key
SUPABASE_STORAGE_BUCKET=documents

# AI Services
GEMINI_API_KEY=your_gemini_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key
OPENAI_API_KEY=your_openai_api_key

# JWT Authentication
JWT_SECRET=your_very_strong_jwt_secret_min_32_characters_long
JWT_EXPIRES_IN=7d
JWT_REFRESH_EXPIRES_IN=30d

# Server Configuration
NODE_ENV=production
PORT=3001
CORS_ORIGIN=http://localhost:3000

# Frontend Environment Variables
NEXT_PUBLIC_API_URL=http://localhost:3001
NEXT_PUBLIC_SUPABASE_URL=https://[YOUR-PROJECT-REF].supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key

# File Upload Configuration
MAX_FILE_SIZE=10485760
ALLOWED_FILE_TYPES=pdf,docx
UPLOAD_DIR=/app/uploads

# PostgreSQL (ë¡œì»¬ DB ì‚¬ìš© ì‹œë§Œ)
# POSTGRES_USER=apas
# POSTGRES_PASSWORD=your_postgres_password
# POSTGRES_DB=apas_db
```

### 2. ë³´ì•ˆ ì„¤ì •

```bash
# í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ ê¶Œí•œ ì„¤ì •
chmod 600 .env.production

# Gitì—ì„œ ì œì™¸ í™•ì¸
echo ".env.production" >> .gitignore
```

---

## ë°°í¬ ì‹¤í–‰

### 1. ì „ì²´ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±

**`scripts/deploy-centos7.sh`**:

```bash
#!/bin/bash
set -e

echo "========================================="
echo "APAS CentOS 7 Docker ë°°í¬ ìŠ¤í¬ë¦½íŠ¸"
echo "========================================="

# 1. í™˜ê²½ í™•ì¸
echo "â¡ï¸  í™˜ê²½ í™•ì¸ ì¤‘..."
if ! command -v docker &> /dev/null; then
    echo "âŒ Dockerê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
    echo "   ./scripts/install-docker-centos7.sh ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”."
    exit 1
fi

if ! command -v docker-compose &> /dev/null; then
    echo "âŒ Docker Composeê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
    exit 1
fi

# 2. ë””ë ‰í† ë¦¬ ìƒì„±
echo "â¡ï¸  ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„± ì¤‘..."
sudo mkdir -p /opt/apas/data/uploads/{documents,generated,temp}
sudo mkdir -p /opt/apas/logs/{frontend,backend}
sudo mkdir -p /opt/apas/backups
sudo chown -R 1000:1000 /opt/apas/data
sudo chmod -R 755 /opt/apas/data

# 3. í™˜ê²½ ë³€ìˆ˜ í™•ì¸
echo "â¡ï¸  í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ì¤‘..."
if [ ! -f ".env.production" ]; then
    echo "âŒ .env.production íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."
    echo "   .env.production íŒŒì¼ì„ ìƒì„±í•˜ì„¸ìš”."
    exit 1
fi

# 4. ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì¤‘ì§€ ë° ì œê±°
echo "â¡ï¸  ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì¤‘ì§€ ì¤‘..."
docker-compose down || true

# 5. Docker ì´ë¯¸ì§€ ë¹Œë“œ
echo "â¡ï¸  Docker ì´ë¯¸ì§€ ë¹Œë“œ ì¤‘..."
docker-compose build --no-cache

# 6. ì»¨í…Œì´ë„ˆ ì‹œì‘
echo "â¡ï¸  ì»¨í…Œì´ë„ˆ ì‹œì‘ ì¤‘..."
docker-compose --env-file .env.production up -d

# 7. ìƒíƒœ í™•ì¸
echo "â¡ï¸  ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸ ì¤‘..."
sleep 5
docker-compose ps

# 8. Health Check
echo "â¡ï¸  Health Check ì‹¤í–‰ ì¤‘..."
sleep 10

# Backend Health Check
if curl -f http://localhost:3001/health &> /dev/null; then
    echo "âœ… Backend: ì •ìƒ"
else
    echo "âŒ Backend: ë¹„ì •ìƒ"
    docker-compose logs backend
fi

# Frontend Health Check
if curl -f http://localhost:3000 &> /dev/null; then
    echo "âœ… Frontend: ì •ìƒ"
else
    echo "âŒ Frontend: ë¹„ì •ìƒ"
    docker-compose logs frontend
fi

echo ""
echo "========================================="
echo "âœ… ë°°í¬ ì™„ë£Œ!"
echo "========================================="
echo ""
echo "ğŸ“Œ ì ‘ì† ì •ë³´:"
echo "   Frontend: http://$(hostname -I | awk '{print $1}'):3000"
echo "   Backend API: http://$(hostname -I | awk '{print $1}'):3001"
echo ""
echo "ğŸ“Œ ë¡œê·¸ í™•ì¸:"
echo "   ì „ì²´: docker-compose logs -f"
echo "   Backend: docker-compose logs -f backend"
echo "   Frontend: docker-compose logs -f frontend"
echo ""
echo "ğŸ“Œ ì—…ë¡œë“œ íŒŒì¼ ìœ„ì¹˜:"
echo "   /opt/apas/data/uploads/"
echo ""
echo "ğŸ“Œ ì»¨í…Œì´ë„ˆ ê´€ë¦¬:"
echo "   ì¤‘ì§€: docker-compose stop"
echo "   ì‹œì‘: docker-compose start"
echo "   ì¬ì‹œì‘: docker-compose restart"
echo "   ì‚­ì œ: docker-compose down"
echo ""
```

### 2. ë°°í¬ ì‹¤í–‰

```bash
# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬
chmod +x scripts/deploy-centos7.sh

# ë°°í¬ ì‹¤í–‰
./scripts/deploy-centos7.sh
```

---

## íŒŒì¼ ì €ì¥ ê´€ë¦¬

### 1. ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
/opt/apas/data/uploads/
â”œâ”€â”€ documents/          # ì›ë³¸ ë¬¸ì„œ (ì‚¬ìš©ì ì—…ë¡œë“œ)
â”‚   â”œâ”€â”€ announcement/   # ê³µê³ ë¬¸
â”‚   â”œâ”€â”€ specification/  # ê³¼ì—…ì§€ì‹œì„œ
â”‚   â””â”€â”€ contract/       # ê³„ì•½ì„œ
â”œâ”€â”€ generated/          # AI ìƒì„± ë¬¸ì„œ
â”‚   â”œâ”€â”€ drafts/        # ì´ˆì•ˆ
â”‚   â””â”€â”€ final/         # ìµœì¢…ë³¸
â””â”€â”€ temp/              # ì„ì‹œ íŒŒì¼ (24ì‹œê°„ í›„ ìë™ ì‚­ì œ)
```

### 2. Backendì—ì„œ íŒŒì¼ ì €ì¥ ì„¤ì •

**`backend/src/config/upload.ts`** (ìƒì„± í•„ìš”):

```typescript
import multer from 'multer'
import path from 'path'
import fs from 'fs'

// ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ ì„¤ì •
const UPLOAD_BASE_DIR = process.env.UPLOAD_DIR || './uploads'

// ë””ë ‰í† ë¦¬ ìƒì„±
const ensureDirectoryExists = (dir: string) => {
  if (!fs.existsSync(dir)) {
    fs.mkdirSync(dir, { recursive: true })
  }
}

// íŒŒì¼ ì €ì¥ ìœ„ì¹˜ ë° ì´ë¦„ ì„¤ì •
const storage = multer.diskStorage({
  destination: (req, file, cb) => {
    const documentType = req.body.type || 'documents'
    const uploadPath = path.join(UPLOAD_BASE_DIR, documentType)

    ensureDirectoryExists(uploadPath)
    cb(null, uploadPath)
  },
  filename: (req, file, cb) => {
    // íŒŒì¼ëª…: timestamp_originalname
    const uniqueSuffix = Date.now() + '_' + Math.round(Math.random() * 1e9)
    const ext = path.extname(file.originalname)
    const basename = path.basename(file.originalname, ext)
    cb(null, `${basename}_${uniqueSuffix}${ext}`)
  },
})

// íŒŒì¼ í•„í„° (PDF, DOCXë§Œ í—ˆìš©)
const fileFilter = (req: any, file: Express.Multer.File, cb: multer.FileFilterCallback) => {
  const allowedTypes = process.env.ALLOWED_FILE_TYPES?.split(',') || ['pdf', 'docx']
  const ext = path.extname(file.originalname).toLowerCase().substring(1)

  if (allowedTypes.includes(ext)) {
    cb(null, true)
  } else {
    cb(new Error(`í—ˆìš©ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. (í—ˆìš©: ${allowedTypes.join(', ')})`))
  }
}

// Multer ì„¤ì •
export const upload = multer({
  storage,
  fileFilter,
  limits: {
    fileSize: parseInt(process.env.MAX_FILE_SIZE || '10485760'), // 10MB
    files: 3, // ìµœëŒ€ 3ê°œ íŒŒì¼
  },
})

// íŒŒì¼ ì‚­ì œ ìœ í‹¸ë¦¬í‹°
export const deleteFile = (filePath: string): Promise<void> => {
  return new Promise((resolve, reject) => {
    fs.unlink(filePath, (err) => {
      if (err) reject(err)
      else resolve()
    })
  })
}

// ì„ì‹œ íŒŒì¼ ì •ë¦¬ (24ì‹œê°„ ì´ìƒ ëœ íŒŒì¼ ì‚­ì œ)
export const cleanupTempFiles = () => {
  const tempDir = path.join(UPLOAD_BASE_DIR, 'temp')
  const maxAge = 24 * 60 * 60 * 1000 // 24ì‹œê°„

  if (!fs.existsSync(tempDir)) return

  fs.readdir(tempDir, (err, files) => {
    if (err) {
      console.error('ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨:', err)
      return
    }

    files.forEach((file) => {
      const filePath = path.join(tempDir, file)
      fs.stat(filePath, (err, stats) => {
        if (err) return

        const age = Date.now() - stats.mtimeMs
        if (age > maxAge) {
          fs.unlink(filePath, (err) => {
            if (err) console.error(`íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ (${file}):`, err)
            else console.log(`ì„ì‹œ íŒŒì¼ ì‚­ì œ: ${file}`)
          })
        }
      })
    })
  })
}
```

### 3. Cron Job ì„¤ì • (ì„ì‹œ íŒŒì¼ ì •ë¦¬)

**`backend/src/jobs/cleanup.ts`**:

```typescript
import cron from 'node-cron'
import { cleanupTempFiles } from '../config/upload'

// ë§¤ì¼ ìƒˆë²½ 3ì‹œì— ì„ì‹œ íŒŒì¼ ì •ë¦¬
export const setupCleanupJob = () => {
  cron.schedule('0 3 * * *', () => {
    console.log('ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‘ì—… ì‹œì‘...')
    cleanupTempFiles()
  })

  console.log('âœ… ì„ì‹œ íŒŒì¼ ì •ë¦¬ Cron Job ì„¤ì • ì™„ë£Œ (ë§¤ì¼ 3:00 AM)')
}
```

### 4. íŒŒì¼ ì ‘ê·¼ ê¶Œí•œ í™•ì¸

```bash
# í˜¸ìŠ¤íŠ¸ì—ì„œ ì—…ë¡œë“œëœ íŒŒì¼ í™•ì¸
ls -lah /opt/apas/data/uploads/documents/

# Docker ì»¨í…Œì´ë„ˆì—ì„œ íŒŒì¼ í™•ì¸
docker exec -it apas-backend ls -lah /app/uploads/documents/

# ê¶Œí•œ ë¬¸ì œ ë°œìƒ ì‹œ
sudo chown -R 1000:1000 /opt/apas/data/uploads
sudo chmod -R 755 /opt/apas/data/uploads
```

---

## ìš´ì˜ ê´€ë¦¬

### 1. ì»¨í…Œì´ë„ˆ ê´€ë¦¬

```bash
# ì „ì²´ ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
docker-compose ps

# ë¡œê·¸ í™•ì¸
docker-compose logs -f
docker-compose logs -f backend
docker-compose logs -f frontend

# ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
docker-compose restart

# íŠ¹ì • ì„œë¹„ìŠ¤ë§Œ ì¬ì‹œì‘
docker-compose restart backend

# ì»¨í…Œì´ë„ˆ ì¤‘ì§€
docker-compose stop

# ì»¨í…Œì´ë„ˆ ì‹œì‘
docker-compose start

# ì»¨í…Œì´ë„ˆ ë° ì´ë¯¸ì§€ ì‚­ì œ
docker-compose down
docker-compose down --rmi all  # ì´ë¯¸ì§€ë„ ì‚­ì œ
```

### 2. ì—…ë°ì´íŠ¸ ë°°í¬

```bash
# 1. ì½”ë“œ ì—…ë°ì´íŠ¸ (Git pull)
git pull origin main

# 2. ì¬ë¹Œë“œ ë° ë°°í¬
docker-compose down
docker-compose build --no-cache
docker-compose --env-file .env.production up -d

# ë˜ëŠ” ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ì¬ì‹¤í–‰
./scripts/deploy-centos7.sh
```

### 3. ë°±ì—…

**ìë™ ë°±ì—… ìŠ¤í¬ë¦½íŠ¸** - **`scripts/backup-centos7.sh`**:

```bash
#!/bin/bash
set -e

BACKUP_DIR="/opt/apas/backups"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_NAME="apas_backup_${TIMESTAMP}"

echo "========================================="
echo "APAS ë°±ì—… ì‹œì‘"
echo "========================================="

# 1. ì—…ë¡œë“œ íŒŒì¼ ë°±ì—…
echo "â¡ï¸  ì—…ë¡œë“œ íŒŒì¼ ë°±ì—… ì¤‘..."
sudo tar -czf "${BACKUP_DIR}/${BACKUP_NAME}_uploads.tar.gz" \
    -C /opt/apas/data uploads/

# 2. ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… (Supabase ì‚¬ìš© ì‹œ ìƒëµ ê°€ëŠ¥)
# echo "â¡ï¸  ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì¤‘..."
# docker exec apas-postgres pg_dump -U apas apas_db | \
#     gzip > "${BACKUP_DIR}/${BACKUP_NAME}_db.sql.gz"

# 3. í™˜ê²½ ë³€ìˆ˜ ë°±ì—…
echo "â¡ï¸  í™˜ê²½ ë³€ìˆ˜ ë°±ì—… ì¤‘..."
cp .env.production "${BACKUP_DIR}/${BACKUP_NAME}.env"

# 4. ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ (30ì¼ ì´ìƒ)
echo "â¡ï¸  ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ ì¤‘..."
find "${BACKUP_DIR}" -name "apas_backup_*" -mtime +30 -delete

echo ""
echo "âœ… ë°±ì—… ì™„ë£Œ: ${BACKUP_NAME}"
echo "   ìœ„ì¹˜: ${BACKUP_DIR}"
ls -lh "${BACKUP_DIR}/${BACKUP_NAME}"*
```

**Cronìœ¼ë¡œ ìë™ ë°±ì—… ì„¤ì •**:

```bash
# Crontab í¸ì§‘
crontab -e

# ë§¤ì¼ ìƒˆë²½ 2ì‹œì— ë°±ì—… ì‹¤í–‰
0 2 * * * /path/to/Water_AI_Report_Gen/scripts/backup-centos7.sh
```

### 4. ëª¨ë‹ˆí„°ë§

**ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§**:

```bash
# Docker ì»¨í…Œì´ë„ˆ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
docker stats

# ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰
df -h /opt/apas

# ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ í¬ê¸°
du -sh /opt/apas/data/uploads/*
```

**ë¡œê·¸ ëª¨ë‹ˆí„°ë§**:

```bash
# ì‹¤ì‹œê°„ ë¡œê·¸ í™•ì¸
docker-compose logs -f --tail=100

# ì—ëŸ¬ ë¡œê·¸ë§Œ í™•ì¸
docker-compose logs backend | grep -i error

# ë¡œê·¸ íŒŒì¼ í¬ê¸° í™•ì¸
ls -lh /opt/apas/logs/backend/*.log
```

### 5. ë°©í™”ë²½ ì„¤ì •

```bash
# í¬íŠ¸ ì˜¤í”ˆ
sudo firewall-cmd --permanent --add-port=3000/tcp  # Frontend
sudo firewall-cmd --permanent --add-port=3001/tcp  # Backend
sudo firewall-cmd --reload

# í™•ì¸
sudo firewall-cmd --list-ports
```

---

## ë³´ì•ˆ ì„¤ì •

### 1. SELinux ì„¤ì • (í•„ìš” ì‹œ)

```bash
# SELinux ìƒíƒœ í™•ì¸
getenforce

# SELinux Permissive ëª¨ë“œ (ì„ì‹œ)
sudo setenforce 0

# SELinux Permissive ëª¨ë“œ (ì˜êµ¬)
sudo sed -i 's/^SELINUX=enforcing/SELINUX=permissive/' /etc/selinux/config
```

### 2. íŒŒì¼ ê¶Œí•œ ê°•í™”

```bash
# ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ ê¶Œí•œ
sudo chmod 755 /opt/apas/data/uploads
sudo chown -R 1000:1000 /opt/apas/data/uploads

# í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ ê¶Œí•œ
chmod 600 .env.production

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ê¶Œí•œ
sudo chmod 755 /opt/apas/logs
```

---

## ë¬¸ì œ í•´ê²°

### 1. ì»¨í…Œì´ë„ˆ ì‹œì‘ ì‹¤íŒ¨

```bash
# ë¡œê·¸ í™•ì¸
docker-compose logs

# íŠ¹ì • ì„œë¹„ìŠ¤ ë¡œê·¸ í™•ì¸
docker-compose logs backend

# ì»¨í…Œì´ë„ˆ ì¬ë¹Œë“œ
docker-compose build --no-cache
docker-compose up -d
```

### 2. íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨

```bash
# ê¶Œí•œ í™•ì¸
ls -lah /opt/apas/data/uploads/

# ê¶Œí•œ ì¬ì„¤ì •
sudo chown -R 1000:1000 /opt/apas/data/uploads
sudo chmod -R 755 /opt/apas/data/uploads

# ì»¨í…Œì´ë„ˆ ë‚´ë¶€ í™•ì¸
docker exec -it apas-backend ls -lah /app/uploads/
```

### 3. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨

```bash
# í™˜ê²½ ë³€ìˆ˜ í™•ì¸
docker-compose exec backend printenv | grep DATABASE

# Supabase ì—°ê²° í…ŒìŠ¤íŠ¸
docker-compose exec backend npx prisma db pull --schema=./prisma/schema.prisma
```

### 4. ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±

```bash
# Docker ì •ë¦¬
docker system prune -a

# ì˜¤ë˜ëœ ë¡œê·¸ ì‚­ì œ
find /opt/apas/logs -name "*.log" -mtime +7 -delete

# ì„ì‹œ íŒŒì¼ ì‚­ì œ
rm -rf /opt/apas/data/uploads/temp/*
```

---

## ì„±ëŠ¥ ìµœì í™”

### 1. Docker ë¦¬ì†ŒìŠ¤ ì œí•œ

**`docker-compose.yml`ì— ì¶”ê°€**:

```yaml
services:
  backend:
    # ... ê¸°ì¡´ ì„¤ì • ...
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
```

### 2. ë¡œê·¸ ë¡œí…Œì´ì…˜

**`/etc/logrotate.d/apas`**:

```
/opt/apas/logs/*/*.log {
    daily
    rotate 7
    compress
    delaycompress
    missingok
    notifempty
    create 0644 root root
}
```

---

## ìš´ì˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì¼ì¼ ì²´í¬

- [ ] ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸ (`docker-compose ps`)
- [ ] ë¡œê·¸ í™•ì¸ (ì—ëŸ¬ ì—†ëŠ”ì§€)
- [ ] ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ í™•ì¸
- [ ] ì—…ë¡œë“œ íŒŒì¼ í™•ì¸

### ì£¼ê°„ ì²´í¬

- [ ] ë°±ì—… í™•ì¸
- [ ] ë¡œê·¸ ë¡œí…Œì´ì…˜ í™•ì¸
- [ ] ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸ í™•ì¸
- [ ] ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### ì›”ê°„ ì²´í¬

- [ ] ë³´ì•ˆ íŒ¨ì¹˜ ì ìš©
- [ ] ë°±ì—… ë³µì› í…ŒìŠ¤íŠ¸
- [ ] ë””ìŠ¤í¬ ì •ë¦¬
- [ ] ì‚¬ìš©ì í”¼ë“œë°± ê²€í† 

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-01-21

**ê¶Œì¥ ë°°í¬ ë°©ì‹**: Docker Compose + Volume Mount
